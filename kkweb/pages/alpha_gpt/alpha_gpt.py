import os
import streamlit as st
import logging
import time
from loguru import logger
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain_community.adapters.openai import convert_openai_messages
import json

# Set up OpenAI API key
os.environ['OPENAI_API_KEY'] = 'sk-H3MkimLzxvofEhZOfGKTveqFqDqfSa6p5vqsHwZv6lkAlLE5'
KEY = os.environ['OPENAI_API_KEY']

# Initialize OpenAI client
client = OpenAI(
    api_key=KEY,
    base_url="https://api.moonshot.cn/v1",
)

# Streamlit page configuration
st.set_page_config(page_title="Alpha GPT", page_icon="ğŸ§ ", layout="wide")
st.title("Alpha GPT")

# Initialize chat history in session state if not already present
if "messages" not in st.session_state:
    st.session_state.messages = []

# Define the FactorGPTAgent class
class FactorGPTAgent:
    def __init__(self, user_prompt):
        self.sources = self.read_file_2_list('./agents/worldquant_101.txt')
        self.user_prompt = user_prompt
        optional_params = {
            "response_format": {"type": "json_object"}
        }
        self.model = ChatOpenAI(
            temperature=0,
            openai_api_key=KEY.strip(),
            model='moonshot-v1-8k',
            base_url="https://api.moonshot.cn/v1",
            max_retries=1,
            model_kwargs=optional_params
        )

    def read_file_2_list(self, filepath):
        with open(filepath, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f.readlines()]

    def build_prompt(self):
        prompt = [{
            "role": "system",
            "content": (
                "ä½ æ˜¯ä¸€ä¸ªé‡åŒ–åˆ†æå¸ˆ. ä½ å¯ä»¥é€šè¿‡é˜…è¯»å¤šä¸ªalphaå› å­è¡¨è¾¾å¼ï¼Œæ€»ç»“å…¶å†…åœ¨è§„å¾‹ï¼Œå¹¶ä¸”å¯ä»¥åˆ›æ–°æ€§çš„ç”Ÿæˆå¯ç”¨çš„å› å­è¡¨è¾¾å¼ã€‚"
                "å¯¹äºç”Ÿæˆçš„è¡¨è¾¾å¼ï¼Œä½ èƒ½å¤Ÿè§£é‡Šå…¶æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸”èƒ½å¤Ÿç”¨æ¸…æ™°ç®€æ´çš„è¯­è¨€è§£é‡Šå…¶å„ä¸ªå˜é‡çš„å«ä¹‰ã€‚\n"
            )
        }, {
            "role": "user",
            "content": (
                f"ç”¨æˆ·æŒ‡ä»¤æè¿°: {self.user_prompt}\n"
                f"æ ·ä¾‹æ•°æ®ï¼š{self.sources}\n"
                f"ä½ çš„ä»»åŠ¡æ˜¯å­¦ä¹ ä»¥ä¸Šèµ„æºä¹‹åï¼Œæ€»ç»“å…¶è§„å¾‹ï¼Œè¾“å‡ºä¸€ä¸ªåŒç±»å‹è¡¨è¾¾å¼ã€‚\n"
                f"ä¹¦å†™è¡¨è¾¾å¼æ—¶ï¼Œè¯·ä»…ä½¿ç”¨æ ·ä¾‹æ•°æ®é‡Œçš„å‡½æ•°ï¼Œæ¯æ¬¡ç”Ÿæˆ1ä¸ªï¼Œç”Ÿæˆçš„è¡¨è¾¾å¼ï¼Œä¸è¦å¸¦Alpha#xxx,æœŸæœ›å› å­çš„ç›¸å…³æ€§ä½\n"
                f"Please return nothing but a JSON in the following format:\n"
                f'{{"expr": "ç”Ÿæˆçš„å› å­è¡¨è¾¾å¼", "desc": "å¯¹è¯¥å› å­è¡¨è¾¾å¼çš„è§£é‡Šè¯´æ˜"}}\n'
            )
        }]
        return prompt

    def run(self):
        lc_messages = convert_openai_messages(self.build_prompt())
        response = self.model.invoke(lc_messages).content
        return json.loads(response)

# Function to stream FactorGPTAgent response
def stream_factor_response(user_prompt):
    factor_agent = FactorGPTAgent(user_prompt)
    response = factor_agent.run()
    response_message = f"å› å­è¡¨è¾¾å¼: {response['expr']}\n\nè§£é‡Š: {response['desc']}"
    logger.info(f"Factor response: {response_message}")
    return response_message

# Main function for Streamlit app
def main():
    st.title("Alpha GPT - ä¸“æ³¨å› å­åˆ†æ")
    st.sidebar.write("### è¯´æ˜")
    st.sidebar.write(
        """
        - æå‡ºä¸å› å­åˆ†æç›¸å…³çš„å…·ä½“é—®é¢˜ã€‚
        - æä¾›æ˜ç¡®çš„éœ€æ±‚æè¿°ã€‚
        - å¦‚æœé—®é¢˜ä¸æ¶‰åŠå› å­åˆ†æï¼Œç³»ç»Ÿå°†æ‹’ç»å›ç­”ã€‚
        """
    )

    logger.info("App started")

    # Prompt for user input and save to chat history
    if prompt := st.chat_input("è¯·æè¿°æ‚¨çš„å› å­åˆ†æéœ€æ±‚"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        logger.info(f"User input: {prompt}")

        # Display the user's query
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])

        # Generate a response based on the user's input
        with st.chat_message("assistant"):
            start_time = time.time()
            logger.info("Generating response")

            with st.spinner("ç”Ÿæˆä¸­..."):
                try:
                    # Check if the query is related to "å› å­" (factor)
                    if "å› å­" in prompt:
                        response_message = stream_factor_response(prompt)
                        st.write(response_message)
                    else:
                        response_message = "è¿™ä¸ªç³»ç»Ÿåªå›ç­”ä¸å› å­åˆ†æç›¸å…³çš„é—®é¢˜ã€‚"
                        st.write(response_message)
                    
                    duration = time.time() - start_time
                    response_message_with_duration = (
                        f"{response_message}\n\nDuration: {duration:.2f} seconds"
                    )
                    st.session_state.messages.append(
                        {"role": "assistant", "content": response_message_with_duration}
                    )
                    logger.info(f"Response: {response_message}, Duration: {duration:.2f} s")
                except Exception as e:
                    st.session_state.messages.append({"role": "assistant", "content": str(e)})
                    st.error("ç”Ÿæˆå“åº”æ—¶å‘ç”Ÿé”™è¯¯ã€‚")
                    logger.error(f"Error: {str(e)}")

# Run the app
if __name__ == "__main__":
    main()
